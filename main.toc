\vspace {2em}
\contentsline {chapter}{Acknowledgements}{ii}{dummy.1}
\vspace {1em}
\contentsline {chapter}{Contents}{iii}{dummy.2}
\contentsline {chapter}{List of Figures}{v}{dummy.4}
\contentsline {chapter}{List of Tables}{vi}{dummy.6}
\contentsline {chapter}{\numberline {1}Wearable devices and new human-machine interfaces: an overview}{1}{chapter.8}
\contentsline {section}{\numberline {1.1}Where to wear an extra eye?}{1}{section.9}
\contentsline {section}{\numberline {1.2}Gestures}{2}{section.14}
\contentsline {section}{\numberline {1.3}In Closing}{4}{section.15}
\contentsline {chapter}{\numberline {2}Computer Vision and Machine Learning techniques used in this thesis}{5}{chapter.16}
\contentsline {section}{\numberline {2.1}Color spaces}{5}{section.17}
\contentsline {section}{\numberline {2.2}Descriptors}{5}{section.18}
\contentsline {subsection}{\numberline {2.2.1}Histograms of Oriented Gradient}{5}{subsection.19}
\contentsline {subsection}{\numberline {2.2.2}Histograms of Optical Flow}{5}{subsection.20}
\contentsline {subsection}{\numberline {2.2.3}MBH}{5}{subsection.21}
\contentsline {section}{\numberline {2.3}Classifiers}{5}{section.22}
\contentsline {subsection}{\numberline {2.3.1}Support Vector Machines}{5}{subsection.23}
\contentsline {subsubsection}{\numberline {2.3.1.1}The separable case}{6}{subsubsection.24}
\contentsline {subsection}{\numberline {2.3.2}Non-separable case}{7}{subsection.31}
\contentsline {subsection}{\numberline {2.3.3}Structured Learning and Structured SVM}{7}{subsection.35}
\contentsline {subsection}{\numberline {2.3.4}Loss Functions}{8}{subsection.38}
\contentsline {subsection}{\numberline {2.3.5}Structured SVM}{8}{subsection.41}
\contentsline {chapter}{\numberline {3}Hand segmentation in ego-centric videos}{10}{chapter.43}
\contentsline {section}{\numberline {3.1}Literature overview}{11}{section.44}
\contentsline {section}{\numberline {3.2}Proposed approach}{12}{section.45}
\contentsline {subsubsection}{\numberline {3.2.0.1}Illumination invariance}{12}{subsubsection.46}
\contentsline {subsubsection}{\numberline {3.2.0.2}Temporal smoothing}{13}{subsubsection.48}
\contentsline {subsubsection}{\numberline {3.2.0.3}Spatial consistency}{14}{subsubsection.51}
\contentsline {section}{\numberline {3.3}Experimental results}{14}{section.59}
\contentsline {subsection}{\numberline {3.3.1}Features performance}{16}{subsection.61}
\contentsline {subsection}{\numberline {3.3.2}Temporal Smoothing and Spatial Consistency}{16}{subsection.63}
\contentsline {subsection}{\numberline {3.3.3}Comparison to related methods}{17}{subsection.65}
\contentsline {chapter}{\numberline {4}Towards ego-vision human-machine interfaces: gesture recognition in the cultural heritage scenario}{18}{chapter.66}
\contentsline {section}{\numberline {4.1}Motivation}{18}{section.67}
\contentsline {section}{\numberline {4.2}Proposed Method}{20}{section.68}
\contentsline {subsection}{\numberline {4.2.1}Camera motion removal}{21}{subsection.74}
\contentsline {subsection}{\numberline {4.2.2}Gesture Description}{21}{subsection.75}
\contentsline {section}{\numberline {4.3}Experimental Results}{22}{section.77}
\contentsline {chapter}{\numberline {5}A sequential implementation for the Odroid-XU developer board}{25}{chapter.89}
\contentsline {subsection}{\numberline {5.0.1}Label Sequence Learning}{25}{subsection.90}
\contentsline {section}{\numberline {5.1}The Odroid-XU board}{27}{section.98}
\contentsline {section}{\numberline {5.2}Implementation}{28}{section.103}
\contentsline {subsection}{\numberline {5.2.1}OpenMP and Neon Intrisics}{29}{subsection.109}
\contentsline {subsection}{\numberline {5.2.2}Further optimizations}{30}{subsection.136}
\contentsline {chapter}{\numberline {6}Conclusion}{31}{chapter.139}
\vspace {2em}
\contentsline {chapter}{\numberline {A}Appendix Title Here}{32}{appendix.140}
\vspace {2em}
\contentsline {chapter}{Bibliography}{33}{dummy.141}
