\vspace {2em}
\contentsline {chapter}{Acknowledgements}{ii}{dummy.1}
\vspace {1em}
\contentsline {chapter}{Contents}{iii}{dummy.2}
\contentsline {chapter}{List of Figures}{v}{dummy.4}
\contentsline {chapter}{List of Tables}{vi}{dummy.6}
\contentsline {chapter}{\numberline {1}Wearable devices and new human-machine interfaces: an overview}{1}{chapter.8}
\contentsline {section}{\numberline {1.1}Where to wear an extra eye?}{1}{section.9}
\contentsline {section}{\numberline {1.2}3D cameras}{2}{section.14}
\contentsline {section}{\numberline {1.3}In Closing}{2}{section.15}
\contentsline {chapter}{\numberline {2}Computer Vision and Machine Learning techniques used in this thesis}{4}{chapter.16}
\contentsline {section}{\numberline {2.1}Color spaces}{4}{section.17}
\contentsline {section}{\numberline {2.2}Descriptors}{4}{section.18}
\contentsline {subsection}{\numberline {2.2.1}Histograms of Oriented Gradient}{4}{subsection.19}
\contentsline {subsection}{\numberline {2.2.2}Histograms of Optical Flow}{4}{subsection.20}
\contentsline {subsection}{\numberline {2.2.3}MBH}{4}{subsection.21}
\contentsline {section}{\numberline {2.3}Classifiers}{4}{section.22}
\contentsline {subsection}{\numberline {2.3.1}Support Vector Machines}{4}{subsection.23}
\contentsline {subsubsection}{\numberline {2.3.1.1}The separable case}{5}{subsubsection.24}
\contentsline {subsection}{\numberline {2.3.2}Non-separable case}{6}{subsection.31}
\contentsline {subsection}{\numberline {2.3.3}Structured Learning and Structured SVM}{6}{subsection.35}
\contentsline {subsection}{\numberline {2.3.4}Loss Functions}{7}{subsection.38}
\contentsline {subsection}{\numberline {2.3.5}Structured SVM}{7}{subsection.41}
\contentsline {chapter}{\numberline {3}Hand segmentation in ego-centric videos}{9}{chapter.43}
\contentsline {section}{\numberline {3.1}Literature overview}{10}{section.44}
\contentsline {section}{\numberline {3.2}Proposed approach}{11}{section.45}
\contentsline {subsubsection}{\numberline {3.2.0.1}Illumination invariance}{11}{subsubsection.46}
\contentsline {subsubsection}{\numberline {3.2.0.2}Temporal smoothing}{12}{subsubsection.48}
\contentsline {subsubsection}{\numberline {3.2.0.3}Spatial consistency}{13}{subsubsection.51}
\contentsline {section}{\numberline {3.3}Experimental results}{13}{section.59}
\contentsline {subsection}{\numberline {3.3.1}Features performance}{15}{subsection.61}
\contentsline {subsection}{\numberline {3.3.2}Temporal Smoothing and Spatial Consistency}{15}{subsection.63}
\contentsline {subsection}{\numberline {3.3.3}Comparison to related methods}{16}{subsection.65}
\contentsline {chapter}{\numberline {4}Towards ego-vision human-machine interfaces: gesture recognition in the cultural heritage scenario}{17}{chapter.66}
\contentsline {section}{\numberline {4.1}Motivation}{17}{section.67}
\contentsline {section}{\numberline {4.2}Proposed Method}{19}{section.68}
\contentsline {subsection}{\numberline {4.2.1}Camera motion removal}{20}{subsection.74}
\contentsline {subsection}{\numberline {4.2.2}Gesture Description}{20}{subsection.75}
\contentsline {section}{\numberline {4.3}Experimental Results}{21}{section.77}
\contentsline {chapter}{\numberline {5}A sequential implementation for the Odroid-XU developer board}{24}{chapter.89}
\contentsline {subsection}{\numberline {5.0.1}Label Sequence Learning}{24}{subsection.90}
\contentsline {section}{\numberline {5.1}The Odroid-XU board}{26}{section.98}
\contentsline {section}{\numberline {5.2}Implementation}{27}{section.103}
\contentsline {subsection}{\numberline {5.2.1}OpenMP and Neon Intrisics}{28}{subsection.109}
\contentsline {subsection}{\numberline {5.2.2}Further optimizations}{29}{subsection.136}
\contentsline {chapter}{\numberline {6}Conclusion}{30}{chapter.139}
\vspace {2em}
\contentsline {chapter}{\numberline {A}Appendix Title Here}{31}{appendix.140}
\vspace {2em}
\contentsline {chapter}{Bibliography}{32}{dummy.141}
